{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pre-trained embedding from the TensorFlow Hub to categorise books\n",
    "\n",
    "Final modelling scenario whereby I am utilzing a pre-trained embedding available from the TensorFlow Hub and code created by AIEngineering [online] available at https://www.youtube.com/watch?v=dkpS2g4K08s. This code csreate an end to end NLP pipeline starting from cleaning text data, setting NLP pipeline, model selection and model evaluation while handling handling imbalanced a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIEngineering\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get cleaned data from CW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\jmd05\\DSM-020\\4. CW1\\Data\\all1.csv\", index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Subject</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Synopsis1</th>\n",
       "      <th>Synopsis2</th>\n",
       "      <th>Synopsis2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my life in red and white</td>\n",
       "      <td>for the very first time world renowned and rev...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781474618267</td>\n",
       "      <td>['first', 'time', 'world', 'renowned', 'revolu...</td>\n",
       "      <td>['first', 'time', 'world', 'renowned', 'revolu...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the accidental footballer</td>\n",
       "      <td>pat nevin never wanted to be a professional fo...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781913183370</td>\n",
       "      <td>['pat', 'nevin', 'never', 'wanted', 'professio...</td>\n",
       "      <td>['pat', 'nevin', 'never', 'want', 'professiona...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sooley</td>\n",
       "      <td>one man seventeen year old samuel sooleyman co...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781529368000</td>\n",
       "      <td>['one', 'man', 'seventeen', 'year', 'old', 'sa...</td>\n",
       "      <td>['one', 'man', 'seventeen', 'year', 'old', 'sa...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mortimer whitehouse gone fishing life death an...</td>\n",
       "      <td>two comedy greats talk life friendship and the...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781788702942</td>\n",
       "      <td>['two', 'comedy', 'greats', 'talk', 'life', 'f...</td>\n",
       "      <td>['two', 'comedy', 'greats', 'talk', 'life', 'f...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the accidental footballer signed edition</td>\n",
       "      <td>signed edition a standard edition is available...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781800960114</td>\n",
       "      <td>['signed', 'edition', 'standard', 'edition', '...</td>\n",
       "      <td>['sign', 'edition', 'standard', 'edition', 'av...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                           my life in red and white   \n",
       "1                          the accidental footballer   \n",
       "2                                             sooley   \n",
       "3  mortimer whitehouse gone fishing life death an...   \n",
       "4           the accidental footballer signed edition   \n",
       "\n",
       "                                            Synopsis         Subject  \\\n",
       "0  for the very first time world renowned and rev...  sports leisure   \n",
       "1  pat nevin never wanted to be a professional fo...  sports leisure   \n",
       "2  one man seventeen year old samuel sooleyman co...  sports leisure   \n",
       "3  two comedy greats talk life friendship and the...  sports leisure   \n",
       "4  signed edition a standard edition is available...  sports leisure   \n",
       "\n",
       "            ISBN                                          Synopsis1  \\\n",
       "0  9781474618267  ['first', 'time', 'world', 'renowned', 'revolu...   \n",
       "1  9781913183370  ['pat', 'nevin', 'never', 'wanted', 'professio...   \n",
       "2  9781529368000  ['one', 'man', 'seventeen', 'year', 'old', 'sa...   \n",
       "3  9781788702942  ['two', 'comedy', 'greats', 'talk', 'life', 'f...   \n",
       "4  9781800960114  ['signed', 'edition', 'standard', 'edition', '...   \n",
       "\n",
       "                                           Synopsis2  Synopsis2_len  \n",
       "0  ['first', 'time', 'world', 'renowned', 'revolu...            149  \n",
       "1  ['pat', 'nevin', 'never', 'want', 'professiona...             98  \n",
       "2  ['one', 'man', 'seventeen', 'year', 'old', 'sa...            105  \n",
       "3  ['two', 'comedy', 'greats', 'talk', 'life', 'f...            109  \n",
       "4  ['sign', 'edition', 'standard', 'edition', 'av...            103  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            object\n",
       "Synopsis         object\n",
       "Subject          object\n",
       "ISBN              int64\n",
       "Synopsis1        object\n",
       "Synopsis2        object\n",
       "Synopsis2_len     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "# See that the target 'Subject' is of 'object' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "romantic fiction               92\n",
       "history                        91\n",
       "sports leisure                 89\n",
       "food drink                     88\n",
       "entertainment                  79\n",
       "spirituality beliefs           75\n",
       "science technology medicine    72\n",
       "business finance law           70\n",
       "Name: Subject, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Subject'].value_counts(dropna=False)\n",
    "# Slight imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmd05\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=['business finance law' 'entertainment' 'food drink' 'history'\n",
      " 'romantic fiction' 'science technology medicine' 'spirituality beliefs'\n",
      " 'sports leisure'], y=0      sports leisure\n",
      "1      sports leisure\n",
      "2      sports leisure\n",
      "3      sports leisure\n",
      "4      sports leisure\n",
      "            ...      \n",
      "760     entertainment\n",
      "761     entertainment\n",
      "762     entertainment\n",
      "764     entertainment\n",
      "765     entertainment\n",
      "Name: Subject, Length: 656, dtype: object as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8913043478260869,\n",
       " 0.9010989010989011,\n",
       " 0.9213483146067416,\n",
       " 0.9318181818181818,\n",
       " 1.0379746835443038,\n",
       " 1.0933333333333333,\n",
       " 1.1388888888888888,\n",
       " 1.1714285714285715]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at adding rebalancing weights\n",
    "class_weights=list(class_weight.compute_class_weight('balanced', np.unique(df['Subject']), df['Subject']))\n",
    "class_weights.sort()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8913043478260869,\n",
       " 1: 0.9010989010989011,\n",
       " 2: 0.9213483146067416,\n",
       " 3: 0.9318181818181818,\n",
       " 4: 1.0379746835443038,\n",
       " 5: 1.0933333333333333,\n",
       " 6: 1.1388888888888888,\n",
       " 7: 1.1714285714285715}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights={}\n",
    "for index, weight in enumerate(class_weights) :\n",
    "  weights[index]=weight\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape      # 656\n",
    "#X_train.shape # 459\n",
    "#X_test.shape  # 197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hijEnYw7V_ey"
   },
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train['Synopsis'].values, X_train['Subject'].values))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test['Synopsis'].values, X_test['Subject'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "u1diITDtD9xD",
    "outputId": "3e9628c2-d4fe-4206-c496-a466c2b87931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synopsis: b'for curious readers young and old a rich and colorful history of religion from humanity s earliest days to our own contentious times in an era of hardening religious attitudes and explosive religious violence this book offers a welcome antidote richard holloway retells the entire history of religion from the dawn of religious belief to the twenty first century with deepest respect and a keen commitment to accuracy writing for those with faith and those without and especially for young readers he encourages curiosity and tolerance accentuates nuance and mystery and calmly restores a sense of the value of faith ranging far beyond the major world religions of judaism islam christianity buddhism and hinduism holloway also examines where religious belief comes from the search for meaning throughout history today s fascinations with scientology and creationism religiously motivated violence hostilities between religious people and secularists and more holloway proves an empathic yet discerning guide to the enduring significance of faith and its power from ancient times to our own', Subject: b'spirituality beliefs'\n"
     ]
    }
   ],
   "source": [
    "for text, target in dataset_train.take(1):\n",
    "  print ('Synopsis: {}, Subject: {}'.format(text, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "posXzJ1PvHZl"
   },
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(['romantic fiction','history','sports leisure','food drink','entertainment','spirituality beliefs',\n",
    "                          'science technology medicine','business finance law']), values=tf.constant([0,1,2,3,4,5,6,7]),\n",
    "    ),\n",
    "    default_value=tf.constant(-1),\n",
    "    name=\"target_encoding\"\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def target(x):\n",
    "  return table.lookup(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.StaticHashTable at 0x1252bf70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDr8nLr8vIe-"
   },
   "outputs": [],
   "source": [
    "def show_batch(dataset, size=1):\n",
    "  for batch, label in dataset.take(size):\n",
    "      print(batch.numpy())\n",
    "      print(target(label).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "YbJgzzAmIqTp",
    "outputId": "62fbced7-57fc-4cd6-8645-366d529a7a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'the old world dying on its feet a new one struggling to be born dublin 1918 in a country doubly ravaged by war and disease nurse julia power works at an understaffed hospital in the city centre where expectant mothers who have come down with an unfamiliar flu are quarantined together into julia s regimented world step two outsiders doctor kathleen lynn on the run from the police and a young volunteer helper bridie sweeney in the darkness and intensity of this tiny ward over the course of three days these women change each other s lives in unexpected ways they lose patients to this baffling pandemic but they also shepherd new life into a fearful world with tireless tenderness and humanity carers and mothers alike somehow do their impossible work in the pull of the stars emma donoghue tells an unforgettable and deeply moving story of love and loss from the bestselling author of the wonder and room'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "show_batch(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6D4lGAezmjL"
   },
   "outputs": [],
   "source": [
    "def fetch(text, labels):\n",
    "  return text, tf.one_hot(target(labels),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQX8hZl60WaK"
   },
   "outputs": [],
   "source": [
    "train_data_f=dataset_train.map(fetch)\n",
    "test_data_f=dataset_test.map(fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "xOzA_Tz4vIcV",
    "outputId": "7c28c8e5-53b5-46d2-b174-51e2ac826b6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'the old world dying on its feet a new one struggling to be born dublin 1918 in a country doubly ravaged by war and disease nurse julia power works at an understaffed hospital in the city centre where expectant mothers who have come down with an unfamiliar flu are quarantined together into julia s regimented world step two outsiders doctor kathleen lynn on the run from the police and a young volunteer helper bridie sweeney in the darkness and intensity of this tiny ward over the course of three days these women change each other s lives in unexpected ways they lose patients to this baffling pandemic but they also shepherd new life into a fearful world with tireless tenderness and humanity carers and mothers alike somehow do their impossible work in the pull of the stars emma donoghue tells an unforgettable and deeply moving story of love and loss from the bestselling author of the wonder and room'>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_data_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "Zad9I-x19Vvo",
    "outputId": "08038420-f188-4873-9c9f-0e167155a8f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'for curious readers young and old a rich and colorful history of religion from humanity s earliest days to our own contentious times in an era of hardening religious attitudes and explosive religious violence this book offers a welcome antidote richard holloway retells the entire history of religion from the dawn of religious belief to the twenty first century with deepest respect and a keen commitment to accuracy writing for those with faith and those without and especially for young readers he encourages curiosity and tolerance accentuates nuance and mystery and calmly restores a sense of the value of faith ranging far beyond the major world religions of judaism islam christianity buddhism and hinduism holloway also examines where religious belief comes from the search for meaning throughout history today s fascinations with scientology and creationism religiously motivated violence hostilities between religious people and secularists and more holloway proves an empathic yet discerning guide to the enduring significance of faith and its power from ancient times to our own',\n",
       "        b'this guided journal will help you cultivate gratitude through the exercise of mindfulness and journaling gratitude a day and night reflection journal will help you center your day around positive feelings and gratitude it\\xe2\\x80\\x99s the perfect place to record and celebrate anything that you are grateful for and to preserve important memories this 90 day journal gives you a path to creating a habit of daily gratitude that you can carry with you throughout your life cultivating gratitude is one of the most potent and important mindfulness exercises and thankfulness has proven to have a positive effect on a person s mental health and general well being each page of the journal includes space to record expressions of gratitude personal affirmations memories of positive interactions and commentaries on the significance of it all the journal is intended for those who want to foster deep reflection as well as for those who simply want to discover the effects of thankfulness having filled the journal with statements of gratitude you will end up with a personal trove of wonderful reflections which can be a source of positive inspiration at any time the journal\\xe2\\x80\\x99s 184 lined acid free pages made from archival paper take both pen and pencil nicely and the back pocket is perfect for holding mementos',\n",
       "        b'shortlisted for the orwell prize for political writing 2020 shortlisted for the british book awards non fiction narrative book of the year 2020 waterstones non fiction book of the month for march 2020 winner of the financial times and mckinsey business book of the year award 2019 winner of the royal society insight investment science book prize 2019 imagine a world where your phone is too big for your hand where your doctor prescribes a drug that is wrong for your body where in a car accident you are 47 more likely to be seriously injured where every week the countless hours of work you do are not recognised or valued if any of this sounds familiar chances are that you re a woman invisible women shows us how in a world largely built for and by men we are systematically ignoring half the population it exposes the gender data gap a gap in our knowledge that is at the root of perpetual systemic discrimination against women and that has created a pervasive but invisible bias with a profound effect on women s lives award winning campaigner and writer caroline criado perez brings together for the first time an impressive range of case studies stories and new research from across the world that illustrate the hidden ways in which women are forgotten and the impact this has on their health and well being from government policy and medical research to technology workplaces urban planning and the media invisible women reveals the biased data that excludes women in making the case for change this powerful and provocative book will make you see the world anew',\n",
       "        b'magisterial immensely readable douglas alexander financial times a compelling history of catastrophes and their consequences from the most brilliant british historian of his generation the times disasters are inherently hard to predict but when catastrophe strikes we ought to be better prepared than the romans were when vesuvius erupted or medieval italians when the black death struck we have science on our side after all yet the responses of many developed countries to a new pathogen from china were badly bungled why while populist rulers certainly performed poorly in the face of the pandemic niall ferguson argues that more profound pathologies were at work pathologies already visible in our responses to earlier disasters drawing from multiple disciplines including economics and network science doom the politics of catastrophe offers not just a history but a general theory of disaster as ferguson shows governments must learn to become less bureaucratic if we are to avoid the impending doom of irreversible decline insightful productively provocative and downright brilliant new york times stimulating thought provoking readers will find much to relish martin bentham evening standard',\n",
       "        b'in 12 rules for life acclaimed public thinker and clinical psychologist jordan b peterson offered an antidote to the chaos in our lives eternal truths applied to modern anxieties his insights have helped millions of readers and resonated powerfully around the world now in this long awaited sequel peterson goes further showing that part of life s meaning comes from reaching out into the domain beyond what we know and adapting to an ever transforming world while an excess of chaos threatens us with uncertainty an excess of order leads to a lack of curiosity and creative vitality beyond order therefore calls on us to balance the two fundamental principles of reality order and chaos \\xc2\\xad and reveals the profound meaning that can be found on the path that divides them in times of instability and suffering peterson reminds us that there are sources of strength on which we can all draw insights borrowed from psychology philosophy and humanity s greatest myths and stories drawing on the hard won truths of ancient wisdom as well as deeply personal lessons from his own life and clinical practice peterson offers twelve new principles to guide readers towards a more courageous truthful and meaningful life'],\n",
       "       dtype=object)>,\n",
       " <tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_labels = next(iter(train_data_f.batch(5)))\n",
    "train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "ifU5cdUp9VnZ",
    "outputId": "d439a3c2-d3cf-4d75-9daa-0f9dfb73ec07"
   },
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, output_shape=[128], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "#hub_layer(train_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "1AI7BhDe9Vif",
    "outputId": "12c70379-9b0f-4d25-a95e-910ca903e85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 124,647,080\n",
      "Trainable params: 124,647,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "#for units in [128,64,32]:\n",
    "for units in [32]:\n",
    "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_HPHq3W9VeT"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSCeGUYF9TlL"
   },
   "outputs": [],
   "source": [
    "train_data_f=train_data_f.shuffle(70000).batch(100)\n",
    "test_data_f=test_data_f.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "E_h5I4StQj5E",
    "outputId": "98f61cb1-2e0c-4a15-9dbc-9a0c1b375d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmd05\\Anaconda3\\lib\\site-packages\\keras\\backend.py:4846: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 120s 28s/step - loss: 2.1391 - accuracy: 0.1373 - val_loss: 2.0454 - val_accuracy: 0.1980\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.9757 - accuracy: 0.2418 - val_loss: 1.9668 - val_accuracy: 0.3046\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.8588 - accuracy: 0.3595 - val_loss: 1.9130 - val_accuracy: 0.3553\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_f,\n",
    "                    epochs=3,\n",
    "                    validation_data=test_data_f,\n",
    "                    verbose=1,\n",
    "                    class_weight=weights,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hy55ceBpjL7E",
    "outputId": "4141c279-216d-4e36-e291-ffa0d7de14f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "MwG1bP-TC5fE",
    "outputId": "244428b1-c662-41ff-96b6-aeb19095e49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.9130 - accuracy: 0.3553\n",
      "[1.9130250215530396, 0.3553299605846405]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(dataset_test.map(fetch).batch(197), verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nQdChwqbFer"
   },
   "outputs": [],
   "source": [
    "test_data, test_labels = next(iter(dataset_test.map(fetch).batch(459)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZ9qnGJ7cHlc"
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzzDvHTAcnIv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "Vz8L4sgJcTqI",
    "outputId": "ad67bc27-14ce-42dc-d46b-7dcd82b60093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.88      0.60        24\n",
      "           1       0.27      0.80      0.41        25\n",
      "           2       0.93      0.35      0.51        37\n",
      "           3       1.00      0.14      0.24        22\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.67      0.17      0.27        24\n",
      "           6       0.14      0.50      0.22        14\n",
      "           7       0.50      0.11      0.17        19\n",
      "\n",
      "    accuracy                           0.36       197\n",
      "   macro avg       0.50      0.37      0.30       197\n",
      "weighted avg       0.52      0.36      0.31       197\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmd05\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels.numpy().argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "KGQ59jwIQjgX",
    "outputId": "7fb0c5b8-d47b-43b7-d330-1442db4b9376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  3,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2, 20,  1,  0,  0,  0,  1,  1],\n",
       "       [ 0, 18, 13,  0,  0,  1,  5,  0],\n",
       "       [ 1,  0,  0,  3,  0,  0, 18,  0],\n",
       "       [12, 10,  0,  0,  0,  1,  9,  0],\n",
       "       [ 4,  7,  0,  0,  0,  4,  8,  1],\n",
       "       [ 3,  4,  0,  0,  0,  0,  7,  0],\n",
       "       [ 3, 11,  0,  0,  0,  0,  3,  2]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_labels.numpy().argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 8), dtype=int32, numpy=\n",
       "array([[21,  3,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2, 20,  1,  0,  0,  0,  1,  1],\n",
       "       [ 0, 18, 13,  0,  0,  1,  5,  0],\n",
       "       [ 1,  0,  0,  3,  0,  0, 18,  0],\n",
       "       [12, 10,  0,  0,  0,  1,  9,  0],\n",
       "       [ 4,  7,  0,  0,  0,  4,  8,  1],\n",
       "       [ 3,  4,  0,  0,  0,  0,  7,  0],\n",
       "       [ 3, 11,  0,  0,  0,  0,  3,  2]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = tf.math.confusion_matrix(test_labels.numpy().argmax(axis=1), y_pred.argmax(axis=1))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (0.4.5)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (0.35.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (3.17.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (1.19.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (0.13.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from tensorboard) (1.39.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from protobuf>=3.6.0->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\jmd05\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorboard\n",
      "Version: 2.6.0\n",
      "Summary: TensorBoard lets you watch Tensors Flow\n",
      "Home-page: https://github.com/tensorflow/tensorboard\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\jmd05\\anaconda3\\lib\\site-packages\n",
      "Requires: absl-py, google-auth-oauthlib, numpy, markdown, setuptools, google-auth, protobuf, tensorboard-plugin-wit, tensorboard-data-server, grpcio, werkzeug, wheel, requests\n",
      "Required-by: tensorflow\n"
     ]
    }
   ],
   "source": [
    "#!pip show tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-110-5f05a87d6c4e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-110-5f05a87d6c4e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python C:\\Users\\jmd05\\Anaconda3\\Lib\\site-packages\\tensorboard\\main.py --logdir=r'C:\\Users\\jmd05\\Anaconda3\\Lib\\site-packages\\tensorboard\\logs\\fit'\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#python C:\\Users\\jmd05\\Anaconda3\\Lib\\site-packages\\tensorboard\\main.py --logdir=r'C:\\Users\\jmd05\\Anaconda3\\Lib\\site-packages\\tensorboard\\logs\\fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kill' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#!kill 7700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xM7snwiBpO4v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9936), started 0:04:27 ago. (Use '!kill 9936' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cb13a235b427fdbb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cb13a235b427fdbb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!kill 7700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMgMTEkgjgLBJHYrQheLmp5",
   "include_colab_link": true,
   "name": "Text classification Tensorflow - Multiclass",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
