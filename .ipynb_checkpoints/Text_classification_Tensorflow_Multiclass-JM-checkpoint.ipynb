{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pre-trained embedding from the TensorFlow Hub to categorise books\n",
    "\n",
    "Final modelling scenario whereby I am utilzing a pre-trained embedding available from the TensorFlow Hub and code created by AIEngineering [online] available at https://www.youtube.com/watch?v=dkpS2g4K08s. This code csreate an end to end NLP pipeline starting from cleaning text data, setting NLP pipeline, model selection and model evaluation while handling handling imbalanced a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "import re\n",
    "import string\n",
    "from functools import reduce\n",
    "\n",
    "# Numeric manipulation\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Charts\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt1\n",
    "# Installed wordcloud in a terminal in Jupyter with this powershell command:\n",
    "# PS C:\\Users\\jmd05\\Documents>cd C:\\Users\\jmd05\\anaconda3\n",
    "# PS C:\\Users\\jmd05\\anaconda3\\> conda install -c conda-forge wordcloud=1.6.0 \n",
    "\n",
    "# Web scraping & APIs\n",
    "headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"}\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from isbnlib import meta, desc, info, is_isbn13, classify\n",
    "from isbnlib.registry import bibformatters\n",
    "import time\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords, webtext\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from scipy.spatial import distance_matrix\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Map any punctuation characters to white space\n",
    "translator=str.maketrans(string.punctuation, ' '*len(string.punctuation)) \n",
    "\n",
    "# Other\n",
    "import warnings\n",
    "\n",
    "# AIEngineering\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get cleaned data from CW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\jmd05\\DSM-020\\4. CW1\\Data\\all1.csv\", index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Subject</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Synopsis1</th>\n",
       "      <th>Synopsis2</th>\n",
       "      <th>Synopsis2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my life in red and white</td>\n",
       "      <td>for the very first time world renowned and rev...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781474618267</td>\n",
       "      <td>['first', 'time', 'world', 'renowned', 'revolu...</td>\n",
       "      <td>['first', 'time', 'world', 'renowned', 'revolu...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the accidental footballer</td>\n",
       "      <td>pat nevin never wanted to be a professional fo...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781913183370</td>\n",
       "      <td>['pat', 'nevin', 'never', 'wanted', 'professio...</td>\n",
       "      <td>['pat', 'nevin', 'never', 'want', 'professiona...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sooley</td>\n",
       "      <td>one man seventeen year old samuel sooleyman co...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781529368000</td>\n",
       "      <td>['one', 'man', 'seventeen', 'year', 'old', 'sa...</td>\n",
       "      <td>['one', 'man', 'seventeen', 'year', 'old', 'sa...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mortimer whitehouse gone fishing life death an...</td>\n",
       "      <td>two comedy greats talk life friendship and the...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781788702942</td>\n",
       "      <td>['two', 'comedy', 'greats', 'talk', 'life', 'f...</td>\n",
       "      <td>['two', 'comedy', 'greats', 'talk', 'life', 'f...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the accidental footballer signed edition</td>\n",
       "      <td>signed edition a standard edition is available...</td>\n",
       "      <td>sports leisure</td>\n",
       "      <td>9781800960114</td>\n",
       "      <td>['signed', 'edition', 'standard', 'edition', '...</td>\n",
       "      <td>['sign', 'edition', 'standard', 'edition', 'av...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                           my life in red and white   \n",
       "1                          the accidental footballer   \n",
       "2                                             sooley   \n",
       "3  mortimer whitehouse gone fishing life death an...   \n",
       "4           the accidental footballer signed edition   \n",
       "\n",
       "                                            Synopsis         Subject  \\\n",
       "0  for the very first time world renowned and rev...  sports leisure   \n",
       "1  pat nevin never wanted to be a professional fo...  sports leisure   \n",
       "2  one man seventeen year old samuel sooleyman co...  sports leisure   \n",
       "3  two comedy greats talk life friendship and the...  sports leisure   \n",
       "4  signed edition a standard edition is available...  sports leisure   \n",
       "\n",
       "            ISBN                                          Synopsis1  \\\n",
       "0  9781474618267  ['first', 'time', 'world', 'renowned', 'revolu...   \n",
       "1  9781913183370  ['pat', 'nevin', 'never', 'wanted', 'professio...   \n",
       "2  9781529368000  ['one', 'man', 'seventeen', 'year', 'old', 'sa...   \n",
       "3  9781788702942  ['two', 'comedy', 'greats', 'talk', 'life', 'f...   \n",
       "4  9781800960114  ['signed', 'edition', 'standard', 'edition', '...   \n",
       "\n",
       "                                           Synopsis2  Synopsis2_len  \n",
       "0  ['first', 'time', 'world', 'renowned', 'revolu...            149  \n",
       "1  ['pat', 'nevin', 'never', 'want', 'professiona...             98  \n",
       "2  ['one', 'man', 'seventeen', 'year', 'old', 'sa...            105  \n",
       "3  ['two', 'comedy', 'greats', 'talk', 'life', 'f...            109  \n",
       "4  ['sign', 'edition', 'standard', 'edition', 'av...            103  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            object\n",
       "Synopsis         object\n",
       "Subject          object\n",
       "ISBN              int64\n",
       "Synopsis1        object\n",
       "Synopsis2        object\n",
       "Synopsis2_len     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "# See that the target 'Subject' is of 'object' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "romantic fiction               92\n",
       "history                        91\n",
       "sports leisure                 89\n",
       "food drink                     88\n",
       "entertainment                  79\n",
       "spirituality beliefs           75\n",
       "science technology medicine    72\n",
       "business finance law           70\n",
       "Name: Subject, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Subject'].value_counts(dropna=False)\n",
    "# Slight imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8913043478260869,\n",
       " 0.9010989010989011,\n",
       " 0.9213483146067416,\n",
       " 0.9318181818181818,\n",
       " 1.0379746835443038,\n",
       " 1.0933333333333333,\n",
       " 1.1388888888888888,\n",
       " 1.1714285714285715]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at adding rebalancing weights\n",
    "class_weights=list(class_weight.compute_class_weight('balanced', np.unique(df['Subject']), df['Subject']))\n",
    "class_weights.sort()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8913043478260869,\n",
       " 1: 0.9010989010989011,\n",
       " 2: 0.9213483146067416,\n",
       " 3: 0.9318181818181818,\n",
       " 4: 1.0379746835443038,\n",
       " 5: 1.0933333333333333,\n",
       " 6: 1.1388888888888888,\n",
       " 7: 1.1714285714285715}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights={}\n",
    "for index, weight in enumerate(class_weights) :\n",
    "  weights[index]=weight\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hijEnYw7V_ey"
   },
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train['Synopsis'].values, X_train['Subject'].values))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test['Synopsis'].values, X_test['Subject'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "u1diITDtD9xD",
    "outputId": "3e9628c2-d4fe-4206-c496-a466c2b87931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synopsis: b'for curious readers young and old a rich and colorful history of religion from humanity s earliest days to our own contentious times in an era of hardening religious attitudes and explosive religious violence this book offers a welcome antidote richard holloway retells the entire history of religion from the dawn of religious belief to the twenty first century with deepest respect and a keen commitment to accuracy writing for those with faith and those without and especially for young readers he encourages curiosity and tolerance accentuates nuance and mystery and calmly restores a sense of the value of faith ranging far beyond the major world religions of judaism islam christianity buddhism and hinduism holloway also examines where religious belief comes from the search for meaning throughout history today s fascinations with scientology and creationism religiously motivated violence hostilities between religious people and secularists and more holloway proves an empathic yet discerning guide to the enduring significance of faith and its power from ancient times to our own', Subject: b'spirituality beliefs'\n",
      "Synopsis: b'this guided journal will help you cultivate gratitude through the exercise of mindfulness and journaling gratitude a day and night reflection journal will help you center your day around positive feelings and gratitude it\\xe2\\x80\\x99s the perfect place to record and celebrate anything that you are grateful for and to preserve important memories this 90 day journal gives you a path to creating a habit of daily gratitude that you can carry with you throughout your life cultivating gratitude is one of the most potent and important mindfulness exercises and thankfulness has proven to have a positive effect on a person s mental health and general well being each page of the journal includes space to record expressions of gratitude personal affirmations memories of positive interactions and commentaries on the significance of it all the journal is intended for those who want to foster deep reflection as well as for those who simply want to discover the effects of thankfulness having filled the journal with statements of gratitude you will end up with a personal trove of wonderful reflections which can be a source of positive inspiration at any time the journal\\xe2\\x80\\x99s 184 lined acid free pages made from archival paper take both pen and pencil nicely and the back pocket is perfect for holding mementos', Subject: b'spirituality beliefs'\n",
      "Synopsis: b'shortlisted for the orwell prize for political writing 2020 shortlisted for the british book awards non fiction narrative book of the year 2020 waterstones non fiction book of the month for march 2020 winner of the financial times and mckinsey business book of the year award 2019 winner of the royal society insight investment science book prize 2019 imagine a world where your phone is too big for your hand where your doctor prescribes a drug that is wrong for your body where in a car accident you are 47 more likely to be seriously injured where every week the countless hours of work you do are not recognised or valued if any of this sounds familiar chances are that you re a woman invisible women shows us how in a world largely built for and by men we are systematically ignoring half the population it exposes the gender data gap a gap in our knowledge that is at the root of perpetual systemic discrimination against women and that has created a pervasive but invisible bias with a profound effect on women s lives award winning campaigner and writer caroline criado perez brings together for the first time an impressive range of case studies stories and new research from across the world that illustrate the hidden ways in which women are forgotten and the impact this has on their health and well being from government policy and medical research to technology workplaces urban planning and the media invisible women reveals the biased data that excludes women in making the case for change this powerful and provocative book will make you see the world anew', Subject: b'science technology medicine'\n",
      "Synopsis: b'magisterial immensely readable douglas alexander financial times a compelling history of catastrophes and their consequences from the most brilliant british historian of his generation the times disasters are inherently hard to predict but when catastrophe strikes we ought to be better prepared than the romans were when vesuvius erupted or medieval italians when the black death struck we have science on our side after all yet the responses of many developed countries to a new pathogen from china were badly bungled why while populist rulers certainly performed poorly in the face of the pandemic niall ferguson argues that more profound pathologies were at work pathologies already visible in our responses to earlier disasters drawing from multiple disciplines including economics and network science doom the politics of catastrophe offers not just a history but a general theory of disaster as ferguson shows governments must learn to become less bureaucratic if we are to avoid the impending doom of irreversible decline insightful productively provocative and downright brilliant new york times stimulating thought provoking readers will find much to relish martin bentham evening standard', Subject: b'history'\n",
      "Synopsis: b'in 12 rules for life acclaimed public thinker and clinical psychologist jordan b peterson offered an antidote to the chaos in our lives eternal truths applied to modern anxieties his insights have helped millions of readers and resonated powerfully around the world now in this long awaited sequel peterson goes further showing that part of life s meaning comes from reaching out into the domain beyond what we know and adapting to an ever transforming world while an excess of chaos threatens us with uncertainty an excess of order leads to a lack of curiosity and creative vitality beyond order therefore calls on us to balance the two fundamental principles of reality order and chaos \\xc2\\xad and reveals the profound meaning that can be found on the path that divides them in times of instability and suffering peterson reminds us that there are sources of strength on which we can all draw insights borrowed from psychology philosophy and humanity s greatest myths and stories drawing on the hard won truths of ancient wisdom as well as deeply personal lessons from his own life and clinical practice peterson offers twelve new principles to guide readers towards a more courageous truthful and meaningful life', Subject: b'spirituality beliefs'\n"
     ]
    }
   ],
   "source": [
    "for text, target in dataset_train.take(5):\n",
    "  print ('Synopsis: {}, Subject: {}'.format(text, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "posXzJ1PvHZl"
   },
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(['romantic fiction','history','sports leisure','food drink','entertainment','spirituality beliefs',\n",
    "                          'science technology medicine','business finance law']), values=tf.constant([0,1,2,3,4,5,6,7]),\n",
    "    ),\n",
    "    default_value=tf.constant(-1),\n",
    "    name=\"target_encoding\"\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def target(x):\n",
    "  return table.lookup(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDr8nLr8vIe-"
   },
   "outputs": [],
   "source": [
    "def show_batch(dataset, size=5):\n",
    "  for batch, label in dataset.take(size):\n",
    "      print(batch.numpy())\n",
    "      print(target(label).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "YbJgzzAmIqTp",
    "outputId": "62fbced7-57fc-4cd6-8645-366d529a7a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'the old world dying on its feet a new one struggling to be born dublin 1918 in a country doubly ravaged by war and disease nurse julia power works at an understaffed hospital in the city centre where expectant mothers who have come down with an unfamiliar flu are quarantined together into julia s regimented world step two outsiders doctor kathleen lynn on the run from the police and a young volunteer helper bridie sweeney in the darkness and intensity of this tiny ward over the course of three days these women change each other s lives in unexpected ways they lose patients to this baffling pandemic but they also shepherd new life into a fearful world with tireless tenderness and humanity carers and mothers alike somehow do their impossible work in the pull of the stars emma donoghue tells an unforgettable and deeply moving story of love and loss from the bestselling author of the wonder and room'\n",
      "0\n",
      "b'the mesmerising new york times bestseller each year eight beautiful girls are chosen as paper girls to serve the king it s the highest honour they could hope for and the most demeaning this year there s a ninth and instead of paper she s made of fire a timely reminder that in the right hands the fantasy genre has things to say about injustice and abuse of power in the real world guardian lei is a member of the paper caste the lowest and most persecuted class of people in ikhara ten years ago her mother was snatched by the royal guards and her fate remains unknown now the guards are back and this time it s lei they re after the girl with the golden eyes whose rumoured beauty has piqued the king s interest over weeks of training in the opulent but oppressive palace lei and eight other girls learn the skills and charm that befit a king s consort there lei does the unthinkable she falls in love her forbidden romance becomes enmeshed with an explosive plot that threatens her world s entire way of life lei still the wide eyed country girl at heart must decide how far she s willing to go for justice and revenge'\n",
      "0\n",
      "b'a moving tribute to the sacrifice and bravery of the fliers of raf bomber command the crew based on interviews with ken cook the crew s sole surviving member recounts the wartime exploits of the members of an avro lancaster crew between 1942 and the war s end gloucestershire born bomb aimer ken cook hard bitten australian pilot jim comans navigator don bowes upper gunner george widdis tail gunner jock bolland flight engineer ken randle and radio operator roy woollford were seven ordinary young men living in extraordinary times risking their lives in freedom s cause in the dark skies above hitler s reich from their earliest beginnings in places as far apart as a cotswold village and the suburbs of sydney through the adventure of training in north america and the dread and danger of the forty five bombing raids they flew with 97 squadron david price describes the crew s wartime experiences with human sympathy allied to a secure technical understanding of one of the raf s most iconic aircraft the drama and anxiety of individual missions to kassel munich and augsburg as well as berlin is evoked with thrilling immediacy while the military events and strategic decisions that drove the raf s area bombing campaign against nazi germany are interwoven deftly with the narrative of the crew s operational careers'\n",
      "1\n",
      "b'a bbc radio 4 book of the week from the moment she hears lev s violin for the first time helena attlee is captivated she is told that it is an italian instrument named after its former russian owner eager to discover all she can about its ancestry and the stories contained within its delicate wooden body she sets out for cremona birthplace of the italian violin this is the beginning of a beguiling journey whose end she could never have anticipated making its way from dusty workshops through alpine forests cool venetian churches glittering florentine courts and far flung russian flea markets lev s violin takes us from the heart of italian culture to its very furthest reaches its story of luthiers and scientists princes and orphans musicians composers travellers and raconteurs swells to a poignant meditation on the power of objects stories and music to shape individual lives and to craft entire cultures'\n",
      "4\n",
      "b'the gripping and shocking story of three generations of the sackler family and their roles in the stories of valium and oxycontin by the prize winning bestselling author of say nothing the sackler name adorns the walls of many storied institutions harvard the metropolitan museum of art oxford the louvre they are one of the richest families in the world known for their lavish donations in the arts and the sciences the source of the family fortune was vague however until it emerged that the sacklers were responsible for making and marketing oxycontin a blockbuster painkiller that was a catalyst for the opioid crisis an international epidemic of drug addiction which has killed nearly half a million people in this masterpiece of narrative reporting and writing patrick radden keefe exhaustively documents the jaw dropping and ferociously compelling reality empire of pain is the story of a dynasty a parable of 21st century greed'\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "show_batch(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6D4lGAezmjL"
   },
   "outputs": [],
   "source": [
    "def fetch(text, labels):\n",
    "  return text, tf.one_hot(target(labels),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQX8hZl60WaK"
   },
   "outputs": [],
   "source": [
    "train_data_f=dataset_train.map(fetch)\n",
    "test_data_f=dataset_test.map(fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "xOzA_Tz4vIcV",
    "outputId": "7c28c8e5-53b5-46d2-b174-51e2ac826b6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'for curious readers young and old a rich and colorful history of religion from humanity s earliest days to our own contentious times in an era of hardening religious attitudes and explosive religious violence this book offers a welcome antidote richard holloway retells the entire history of religion from the dawn of religious belief to the twenty first century with deepest respect and a keen commitment to accuracy writing for those with faith and those without and especially for young readers he encourages curiosity and tolerance accentuates nuance and mystery and calmly restores a sense of the value of faith ranging far beyond the major world religions of judaism islam christianity buddhism and hinduism holloway also examines where religious belief comes from the search for meaning throughout history today s fascinations with scientology and creationism religiously motivated violence hostilities between religious people and secularists and more holloway proves an empathic yet discerning guide to the enduring significance of faith and its power from ancient times to our own'>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "Zad9I-x19Vvo",
    "outputId": "08038420-f188-4873-9c9f-0e167155a8f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'for curious readers young and old a rich and colorful history of religion from humanity s earliest days to our own contentious times in an era of hardening religious attitudes and explosive religious violence this book offers a welcome antidote richard holloway retells the entire history of religion from the dawn of religious belief to the twenty first century with deepest respect and a keen commitment to accuracy writing for those with faith and those without and especially for young readers he encourages curiosity and tolerance accentuates nuance and mystery and calmly restores a sense of the value of faith ranging far beyond the major world religions of judaism islam christianity buddhism and hinduism holloway also examines where religious belief comes from the search for meaning throughout history today s fascinations with scientology and creationism religiously motivated violence hostilities between religious people and secularists and more holloway proves an empathic yet discerning guide to the enduring significance of faith and its power from ancient times to our own',\n",
       "        b'this guided journal will help you cultivate gratitude through the exercise of mindfulness and journaling gratitude a day and night reflection journal will help you center your day around positive feelings and gratitude it\\xe2\\x80\\x99s the perfect place to record and celebrate anything that you are grateful for and to preserve important memories this 90 day journal gives you a path to creating a habit of daily gratitude that you can carry with you throughout your life cultivating gratitude is one of the most potent and important mindfulness exercises and thankfulness has proven to have a positive effect on a person s mental health and general well being each page of the journal includes space to record expressions of gratitude personal affirmations memories of positive interactions and commentaries on the significance of it all the journal is intended for those who want to foster deep reflection as well as for those who simply want to discover the effects of thankfulness having filled the journal with statements of gratitude you will end up with a personal trove of wonderful reflections which can be a source of positive inspiration at any time the journal\\xe2\\x80\\x99s 184 lined acid free pages made from archival paper take both pen and pencil nicely and the back pocket is perfect for holding mementos',\n",
       "        b'shortlisted for the orwell prize for political writing 2020 shortlisted for the british book awards non fiction narrative book of the year 2020 waterstones non fiction book of the month for march 2020 winner of the financial times and mckinsey business book of the year award 2019 winner of the royal society insight investment science book prize 2019 imagine a world where your phone is too big for your hand where your doctor prescribes a drug that is wrong for your body where in a car accident you are 47 more likely to be seriously injured where every week the countless hours of work you do are not recognised or valued if any of this sounds familiar chances are that you re a woman invisible women shows us how in a world largely built for and by men we are systematically ignoring half the population it exposes the gender data gap a gap in our knowledge that is at the root of perpetual systemic discrimination against women and that has created a pervasive but invisible bias with a profound effect on women s lives award winning campaigner and writer caroline criado perez brings together for the first time an impressive range of case studies stories and new research from across the world that illustrate the hidden ways in which women are forgotten and the impact this has on their health and well being from government policy and medical research to technology workplaces urban planning and the media invisible women reveals the biased data that excludes women in making the case for change this powerful and provocative book will make you see the world anew',\n",
       "        b'magisterial immensely readable douglas alexander financial times a compelling history of catastrophes and their consequences from the most brilliant british historian of his generation the times disasters are inherently hard to predict but when catastrophe strikes we ought to be better prepared than the romans were when vesuvius erupted or medieval italians when the black death struck we have science on our side after all yet the responses of many developed countries to a new pathogen from china were badly bungled why while populist rulers certainly performed poorly in the face of the pandemic niall ferguson argues that more profound pathologies were at work pathologies already visible in our responses to earlier disasters drawing from multiple disciplines including economics and network science doom the politics of catastrophe offers not just a history but a general theory of disaster as ferguson shows governments must learn to become less bureaucratic if we are to avoid the impending doom of irreversible decline insightful productively provocative and downright brilliant new york times stimulating thought provoking readers will find much to relish martin bentham evening standard',\n",
       "        b'in 12 rules for life acclaimed public thinker and clinical psychologist jordan b peterson offered an antidote to the chaos in our lives eternal truths applied to modern anxieties his insights have helped millions of readers and resonated powerfully around the world now in this long awaited sequel peterson goes further showing that part of life s meaning comes from reaching out into the domain beyond what we know and adapting to an ever transforming world while an excess of chaos threatens us with uncertainty an excess of order leads to a lack of curiosity and creative vitality beyond order therefore calls on us to balance the two fundamental principles of reality order and chaos \\xc2\\xad and reveals the profound meaning that can be found on the path that divides them in times of instability and suffering peterson reminds us that there are sources of strength on which we can all draw insights borrowed from psychology philosophy and humanity s greatest myths and stories drawing on the hard won truths of ancient wisdom as well as deeply personal lessons from his own life and clinical practice peterson offers twelve new principles to guide readers towards a more courageous truthful and meaningful life'],\n",
       "       dtype=object)>,\n",
       " <tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_labels = next(iter(train_data_f.batch(5)))\n",
    "train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "ifU5cdUp9VnZ",
    "outputId": "d439a3c2-d3cf-4d75-9daa-0f9dfb73ec07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[ 1.64101779e+00,  1.09652907e-01,  1.00001007e-01,\n",
       "        -2.85438001e-01,  6.83002546e-02,  5.10165952e-02,\n",
       "         2.34609097e-01,  3.72527400e-03, -1.07460707e-01,\n",
       "         3.07002336e-01,  3.48766237e-01, -2.98062950e-01,\n",
       "        -5.96389949e-01, -1.90483078e-01, -3.67415577e-01,\n",
       "        -6.65464848e-02, -5.73120952e-01,  1.07594058e-01,\n",
       "        -1.51422203e-01,  9.72040236e-01,  1.83290526e-01,\n",
       "        -9.65867490e-02, -2.24603061e-02, -2.23811105e-01,\n",
       "         1.43597379e-01, -5.74837267e-01,  4.49375093e-01,\n",
       "         1.04780287e-01, -5.34029715e-02, -1.64000601e-01,\n",
       "        -1.28825128e-01,  2.62997672e-02,  1.78510562e-01,\n",
       "        -4.91137467e-02,  2.73741871e-01, -2.00332642e-01,\n",
       "        -1.90475762e-01, -2.87243515e-01, -5.72264344e-02,\n",
       "         3.14799875e-01, -3.67510706e-01, -2.53344864e-01,\n",
       "        -1.78415611e-01,  3.23827803e-01,  1.40781835e-01,\n",
       "        -1.49370342e-01, -1.19922146e-01, -4.04885337e-02,\n",
       "         2.03817010e-01, -2.57625598e-02,  2.10018516e-01,\n",
       "        -2.08616555e-01,  5.48057258e-01,  2.35099979e-02,\n",
       "         2.35183716e-01, -2.26473555e-01,  4.62890297e-01,\n",
       "         5.52411601e-02,  1.11119166e-01,  3.03710401e-02,\n",
       "        -4.52348620e-01,  3.52349579e-01, -2.86096856e-02,\n",
       "         9.23644826e-02, -1.04148693e-01,  6.13943189e-02,\n",
       "         2.43069246e-01, -2.82484770e-01,  4.93677944e-01,\n",
       "         5.61128138e-03, -3.35718125e-01, -3.08107976e-02,\n",
       "         2.27392226e-01,  2.25011125e-01,  1.32812381e-01,\n",
       "         5.30678928e-01,  2.19099134e-01, -3.24941874e-01,\n",
       "        -2.64914155e-01,  3.52505851e-03, -8.15179795e-02,\n",
       "        -3.98557603e-01, -4.46635693e-01,  1.32721722e-01,\n",
       "         1.02882914e-01, -2.65003324e-01, -6.41808271e-01,\n",
       "         4.38644081e-01,  6.25499964e-01,  6.30374253e-01,\n",
       "         6.31532744e-02,  4.86580431e-01, -1.91367134e-01,\n",
       "         2.50066638e-01,  4.72704433e-02,  3.65437478e-01,\n",
       "         7.44119138e-02, -3.73939365e-01, -2.65780032e-01,\n",
       "         5.33236638e-02, -1.48659870e-01,  6.29646406e-02,\n",
       "         5.43087780e-01,  3.02766740e-01,  2.72734582e-01,\n",
       "        -8.81510377e-02,  3.79686728e-02,  4.64890987e-01,\n",
       "        -2.36060202e-01,  3.99894059e-01, -2.28019968e-01,\n",
       "        -1.93589509e-01, -3.41973782e-01, -4.75083478e-04,\n",
       "         6.32337704e-02, -2.42673531e-01,  5.70977777e-02,\n",
       "        -5.26772618e-01,  2.80822158e-01,  6.35634512e-02,\n",
       "         3.60155441e-02, -2.74944186e-01,  9.09776166e-02,\n",
       "         2.13571712e-01, -2.87639618e-01, -2.82692820e-01,\n",
       "         1.18075937e-01, -7.08437636e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, output_shape=[128], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "1AI7BhDe9Vif",
    "outputId": "12c70379-9b0f-4d25-a95e-910ca903e85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 124,686,312\n",
      "Trainable params: 124,686,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "for units in [128, 128, 64 , 32]:\n",
    "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_HPHq3W9VeT"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSCeGUYF9TlL"
   },
   "outputs": [],
   "source": [
    "train_data_f=train_data_f.shuffle(70000).batch(512)\n",
    "test_data_f=test_data_f.batch(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "E_h5I4StQj5E",
    "outputId": "98f61cb1-2e0c-4a15-9dbc-9a0c1b375d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmd05\\Anaconda3\\lib\\site-packages\\keras\\backend.py:4846: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[973771,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node Adam/Adam/update/mul_1 (defined at <ipython-input-48-6a6eda8a7550>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1408]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6a6eda8a7550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(train_data_f,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data_f\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     class_weight=weights)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[973771,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node Adam/Adam/update/mul_1 (defined at <ipython-input-48-6a6eda8a7550>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1408]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_f,\n",
    "                    epochs=4,\n",
    "                    validation_data=test_data_f,\n",
    "                    verbose=1,\n",
    "                    class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hy55ceBpjL7E",
    "outputId": "4141c279-216d-4e36-e291-ffa0d7de14f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11491"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "MwG1bP-TC5fE",
    "outputId": "244428b1-c662-41ff-96b6-aeb19095e49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.1696 - accuracy: 0.8739\n",
      "[1.1696072816848755, 0.8739013075828552]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(dataset_test.map(fetch).batch(11491), verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nQdChwqbFer"
   },
   "outputs": [],
   "source": [
    "test_data, test_labels = next(iter(dataset_test.map(fetch).batch(45963)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZ9qnGJ7cHlc"
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzzDvHTAcnIv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "Vz8L4sgJcTqI",
    "outputId": "ad67bc27-14ce-42dc-d46b-7dcd82b60093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      4295\n",
      "           1       0.85      0.86      0.86      2583\n",
      "           2       0.93      0.92      0.92      2015\n",
      "           3       0.87      0.82      0.85      1461\n",
      "           4       0.81      0.84      0.82       611\n",
      "           5       0.55      0.84      0.66       526\n",
      "\n",
      "    accuracy                           0.87     11491\n",
      "   macro avg       0.82      0.86      0.84     11491\n",
      "weighted avg       0.88      0.87      0.88     11491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels.numpy().argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rduQJeGyVbA5"
   },
   "source": [
    "Classification Report with no class weights assigned\n",
    "           \n",
    "\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      0.91      0.92      4295\n",
    "           1       0.84      0.88      0.86      2583\n",
    "           2       0.90      0.94      0.92      2015\n",
    "           3       0.86      0.84      0.85      1461\n",
    "           4       0.86      0.78      0.81       611\n",
    "           5       0.69      0.62      0.65       526\n",
    "\n",
    "    accuracy                           0.88     11491\n",
    "   macro avg       0.85      0.83      0.84     11491\n",
    "weighted avg       0.88      0.88      0.88     11491\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "KGQ59jwIQjgX",
    "outputId": "7fb0c5b8-d47b-43b7-d330-1442db4b9376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3815,  167,   76,   32,   80,  125],\n",
       "       [ 125, 2222,   13,  109,   10,  104],\n",
       "       [  37,   21, 1848,   23,   21,   65],\n",
       "       [  37,  162,   30, 1204,    5,   23],\n",
       "       [  18,   18,   11,    4,  511,   49],\n",
       "       [  29,   21,   17,   10,    7,  442]])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_labels.numpy().argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ixm_2WMmHHt"
   },
   "source": [
    "Confusion matrix without weights assigned\n",
    "\n",
    "```\n",
    "array([[3910,  165,   80,   34,   50,   56],\n",
    "       [ 128, 2274,   20,  128,    3,   30],\n",
    "       [  36,   27, 1893,   18,   16,   25],\n",
    "       [  41,  149,   29, 1227,    5,   10],\n",
    "       [  41,   35,   30,    6,  474,   25],\n",
    "       [  72,   50,   60,   14,    5,  325]])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wC7ymBCknK98"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bo6sh1pGnK6B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhtjA7qGnK07"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQqC8MAknJD4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMjeT_DkpPQ2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nWmBBwIpPMx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSGPqXKcpPI1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjVDPmZDpPEo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfAACV1ipO-d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xM7snwiBpO4v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzfPjub9pOxl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMgMTEkgjgLBJHYrQheLmp5",
   "include_colab_link": true,
   "name": "Text classification Tensorflow - Multiclass",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
